{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "90320daa-3daf-4e62-bde7-71762acb74b6",
   "metadata": {},
   "source": [
    "## Advanced Tokenization, Stemming, Lemmatization & Stopword\n",
    "\n",
    "Natural Language Processing (NLP) by exploring more tokenization techniques, generating and learning about stemming, lemmatization, and stopwords."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8887d09c-f00e-4a9b-a163-6cdb36d8c327",
   "metadata": {},
   "source": [
    "# Whitespace Tokenization \n",
    "**Definition:** Splits text based on whitespace (spaces, tabs, newlines) without removing punctuation.\n",
    "- Useful when punctuation should be preserved as part of the tokens.\n",
    "- Faster but less precise than other tokenizers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1871145e-c21e-4d0f-8a66-d2afa7c7f571",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import nltk\n",
    "#nltk.download()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a3b703d1-3fa4-4fa7-91fd-1bbbb2cfc889",
   "metadata": {},
   "outputs": [],
   "source": [
    "AI = '''Artificial Intelligence refers to the intelligence of machines. This is in contrast to the natural intelligence of\n",
    "humans and animals. With Artificial Intelligence, machines perform functions such as learning, planning, reasoning and\n",
    "problem-solving. Most noteworthy, Artificial Intelligence is the simulation of human intelligence by machines.\n",
    "It is probably the fastest-growing development in the World of technology and innovation. Furthermore, many experts believe\n",
    "AI could solve major challenges and crisis situations.'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "56a810a3-241f-42f9-880f-e7f8fb444098",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Artificial Intelligence refers to the intelligence of machines. This is in contrast to the natural intelligence of\\nhumans and animals. With Artificial Intelligence, machines perform functions such as learning, planning, reasoning and\\nproblem-solving. Most noteworthy, Artificial Intelligence is the simulation of human intelligence by machines.\\nIt is probably the fastest-growing development in the World of technology and innovation. Furthermore, many experts believe\\nAI could solve major challenges and crisis situations.'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "AI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "0a7cff51-61c0-42a4-8a31-fd8f1a95efd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import word_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "b8285f0d-6ca3-4ad4-ae19-bc70db63ae63",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Artificial',\n",
       " 'Intelligence',\n",
       " 'refers',\n",
       " 'to',\n",
       " 'the',\n",
       " 'intelligence',\n",
       " 'of',\n",
       " 'machines',\n",
       " '.',\n",
       " 'This',\n",
       " 'is',\n",
       " 'in',\n",
       " 'contrast',\n",
       " 'to',\n",
       " 'the',\n",
       " 'natural',\n",
       " 'intelligence',\n",
       " 'of',\n",
       " 'humans',\n",
       " 'and',\n",
       " 'animals',\n",
       " '.',\n",
       " 'With',\n",
       " 'Artificial',\n",
       " 'Intelligence',\n",
       " ',',\n",
       " 'machines',\n",
       " 'perform',\n",
       " 'functions',\n",
       " 'such',\n",
       " 'as',\n",
       " 'learning',\n",
       " ',',\n",
       " 'planning',\n",
       " ',',\n",
       " 'reasoning',\n",
       " 'and',\n",
       " 'problem-solving',\n",
       " '.',\n",
       " 'Most',\n",
       " 'noteworthy',\n",
       " ',',\n",
       " 'Artificial',\n",
       " 'Intelligence',\n",
       " 'is',\n",
       " 'the',\n",
       " 'simulation',\n",
       " 'of',\n",
       " 'human',\n",
       " 'intelligence',\n",
       " 'by',\n",
       " 'machines',\n",
       " '.',\n",
       " 'It',\n",
       " 'is',\n",
       " 'probably',\n",
       " 'the',\n",
       " 'fastest-growing',\n",
       " 'development',\n",
       " 'in',\n",
       " 'the',\n",
       " 'World',\n",
       " 'of',\n",
       " 'technology',\n",
       " 'and',\n",
       " 'innovation',\n",
       " '.',\n",
       " 'Furthermore',\n",
       " ',',\n",
       " 'many',\n",
       " 'experts',\n",
       " 'believe',\n",
       " 'AI',\n",
       " 'could',\n",
       " 'solve',\n",
       " 'major',\n",
       " 'challenges',\n",
       " 'and',\n",
       " 'crisis',\n",
       " 'situations',\n",
       " '.']"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "AI_tokens = word_tokenize(AI)\n",
    "AI_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "e06056d9-b56e-4760-bc92-5268d751def4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Artificial',\n",
       " 'Intelligence',\n",
       " 'refers',\n",
       " 'to',\n",
       " 'the',\n",
       " 'intelligence',\n",
       " 'of',\n",
       " 'machines.',\n",
       " 'This',\n",
       " 'is',\n",
       " 'in',\n",
       " 'contrast',\n",
       " 'to',\n",
       " 'the',\n",
       " 'natural',\n",
       " 'intelligence',\n",
       " 'of',\n",
       " 'humans',\n",
       " 'and',\n",
       " 'animals.',\n",
       " 'With',\n",
       " 'Artificial',\n",
       " 'Intelligence,',\n",
       " 'machines',\n",
       " 'perform',\n",
       " 'functions',\n",
       " 'such',\n",
       " 'as',\n",
       " 'learning,',\n",
       " 'planning,',\n",
       " 'reasoning',\n",
       " 'and',\n",
       " 'problem-solving.',\n",
       " 'Most',\n",
       " 'noteworthy,',\n",
       " 'Artificial',\n",
       " 'Intelligence',\n",
       " 'is',\n",
       " 'the',\n",
       " 'simulation',\n",
       " 'of',\n",
       " 'human',\n",
       " 'intelligence',\n",
       " 'by',\n",
       " 'machines.',\n",
       " 'It',\n",
       " 'is',\n",
       " 'probably',\n",
       " 'the',\n",
       " 'fastest-growing',\n",
       " 'development',\n",
       " 'in',\n",
       " 'the',\n",
       " 'World',\n",
       " 'of',\n",
       " 'technology',\n",
       " 'and',\n",
       " 'innovation.',\n",
       " 'Furthermore,',\n",
       " 'many',\n",
       " 'experts',\n",
       " 'believe',\n",
       " 'AI',\n",
       " 'could',\n",
       " 'solve',\n",
       " 'major',\n",
       " 'challenges',\n",
       " 'and',\n",
       " 'crisis',\n",
       " 'situations.']"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.tokenize import WhitespaceTokenizer\n",
    "wt = WhitespaceTokenizer().tokenize(AI)\n",
    "wt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "df7f3f89-7b18-4041-8def-a9c659707433",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "70\n"
     ]
    }
   ],
   "source": [
    "print(len(wt))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "478ade74-390a-41a3-8aca-9339bc6dcee6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Good apple cost $3.88 in hyd.Please buy two of them. Thanks.'"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s = 'Good apple cost $3.88 in hyd.Please buy two of them. Thanks.'\n",
    "s"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5041fef-b265-4b91-987c-adb99582fb88",
   "metadata": {},
   "source": [
    "# WordPunct Tokenization \n",
    "**Definition:** Splits words and punctuation into separate tokens.\n",
    "\n",
    "- Numbers, punctuation marks, and words are treated individually"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "7285d599-e052-4a9e-a2f6-e216552c4723",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Good apple cost $3.88 in Hyderabad. Please buy two of them. Thanks.'"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.tokenize import wordpunct_tokenize\n",
    "\n",
    "s = 'Good apple cost $3.88 in Hyderabad. Please buy two of them. Thanks.'\n",
    "s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "9b8fcf5a-a8fc-4092-8b9b-478ff0e34f17",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Good', 'apple', 'cost', '$', '3', '.', '88', 'in', 'Hyderabad', '.', 'Please', 'buy', 'two', 'of', 'them', '.', 'Thanks', '.']\n"
     ]
    }
   ],
   "source": [
    "print(wordpunct_tokenize(s))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "8ae1b2eb-fa4b-4463-bb72-1f6b02ed2b44",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18\n"
     ]
    }
   ],
   "source": [
    "print(len(wordpunct_tokenize(s)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "eac4c46d-1aa2-4b2e-8ba6-d85eecfd7700",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Artificial', 'Intelligence', 'refers', 'to', 'the', 'intelligence', 'of', 'machines', '.', 'This', 'is', 'in', 'contrast', 'to', 'the', 'natural', 'intelligence', 'of', 'humans', 'and', 'animals', '.', 'With', 'Artificial', 'Intelligence', ',', 'machines', 'perform', 'functions', 'such', 'as', 'learning', ',', 'planning', ',', 'reasoning', 'and', 'problem', '-', 'solving', '.', 'Most', 'noteworthy', ',', 'Artificial', 'Intelligence', 'is', 'the', 'simulation', 'of', 'human', 'intelligence', 'by', 'machines', '.', 'It', 'is', 'probably', 'the', 'fastest', '-', 'growing', 'development', 'in', 'the', 'World', 'of', 'technology', 'and', 'innovation', '.', 'Furthermore', ',', 'many', 'experts', 'believe', 'AI', 'could', 'solve', 'major', 'challenges', 'and', 'crisis', 'situations', '.']\n",
      "85\n"
     ]
    }
   ],
   "source": [
    "\n",
    "w_p = wordpunct_tokenize(AI)\n",
    "print(w_p)\n",
    "print(len(w_p))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7557c683-e8d5-4f54-947b-93e707163387",
   "metadata": {},
   "source": [
    "# Stemming\n",
    "\n",
    "**Definition:** Reduces words to their root form, often by chopping off suffixes. Types:\n",
    "\n",
    "- Porter Stemmer – Basic and widely used, but may not handle all words well.\n",
    "- Lancaster Stemmer – More aggressive, sometimes over-stems words.\n",
    "- Snowball Stemmer – Advanced, supports multiple languages\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "0e9d1842-7be2-46d9-b90f-a52ef55720db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "give : give\n",
      "giving : give\n",
      "given : given\n",
      "gaved : gave\n",
      "thinking : think\n",
      "loving : love\n",
      "maximum : maximum\n",
      "student : student\n",
      "written : written\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from nltk.stem import PorterStemmer, LancasterStemmer, SnowballStemmer\n",
    "\n",
    "words_to_stem=['give','giving','given','gaved','thinking','loving','maximum','student','written']\n",
    "\n",
    "for words in words_to_stem:\n",
    "    print(words+ ' : ' +pst.stem(words))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "117a7bfe-2317-4988-92e7-893309854ae2",
   "metadata": {},
   "source": [
    "## PorterStemmer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "fb0317a4-5c54-43ef-bcaa-34fc5604e8c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import PorterStemmer\n",
    "pst = PorterStemmer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "18447d36-c6d5-4e01-ba49-8a377caf8954",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'affect'"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pst.stem('affection')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "a8673ce6-09c0-4f99-ae3f-aae5078fbe5f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'play'"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pst.stem('playing')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "c1225783-8a31-4271-b5ec-d3a2d45ad630",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'maximum'"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pst.stem('maximum')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fe459a6-93d6-45a5-9cd0-e88e195360f9",
   "metadata": {},
   "source": [
    "## LancasterStemmer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "06e33de7-a277-47d9-b8c2-dbc68d660329",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "give : giv\n",
      "giving : giv\n",
      "given : giv\n",
      "gaved : gav\n",
      "thinking : think\n",
      "loving : lov\n",
      "maximum : maxim\n",
      "student : stud\n",
      "written : writ\n"
     ]
    }
   ],
   "source": [
    "from nltk.stem import LancasterStemmer\n",
    "lst = LancasterStemmer()\n",
    "\n",
    "for words in words_to_stem:\n",
    "    print(words+ ' : ' +lst.stem(words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "a6d902ac-b324-4899-821a-7773f7fb86a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "give : give\n",
      "giving : give\n",
      "given : given\n",
      "gaved : gave\n",
      "thinking : think\n",
      "loving : love\n",
      "maximum : maximum\n",
      "student : student\n",
      "written : written\n"
     ]
    }
   ],
   "source": [
    "from nltk.stem import SnowballStemmer\n",
    "lst = SnowballStemmer('english')\n",
    "\n",
    "for words in words_to_stem:\n",
    "    print(words+ ' : ' +lst.stem(words))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecfb66ae-17b9-431d-993a-0b3462d7a838",
   "metadata": {},
   "source": [
    "## SnowballStemmer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "283a45ec-ad9f-4792-9e03-c56eb21ae22a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'autobahn'"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stemmer = SnowballStemmer(\"german\")     # choose a Language\n",
    ">>> stemmer.stem(\"Autobahnen\")          # Stem a word"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "542ea556-2f66-4620-b553-aa9e32fd0667",
   "metadata": {},
   "source": [
    "# Lemmatization\n",
    "\n",
    "**Definition:** Reduces words to their dictionary (lemma) form, considering meaning and grammar.\n",
    "\n",
    "- More accurate than stemming because it uses vocabulary and morphological analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "90f2d142-3c80-4202-824a-4ed0ac4b94f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import wordnet\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "word_lem = WordNetLemmatizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "1cddeb72-a59d-4547-9201-76e8e8a461e3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['give',\n",
       " 'giving',\n",
       " 'given',\n",
       " 'gaved',\n",
       " 'thinking',\n",
       " 'loving',\n",
       " 'maximum',\n",
       " 'student',\n",
       " 'written']"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words_to_stem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "96188864-26a8-4e5f-8f29-07c39f5d76b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "give : give\n",
      "giving : giving\n",
      "given : given\n",
      "gaved : gaved\n",
      "thinking : thinking\n",
      "loving : loving\n",
      "maximum : maximum\n",
      "student : student\n",
      "written : written\n"
     ]
    }
   ],
   "source": [
    "for words in words_to_stem:\n",
    "    print(words+ ' : ' +word_lem.lemmatize(words))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "344985c9-fe40-450d-a592-a33b0720862f",
   "metadata": {},
   "source": [
    "# Stopwords\n",
    "\n",
    "**Definition:** Commonly used words (e.g., \"the\", \"is\", \"in\") that are often removed in NLP tasks.\n",
    "\n",
    "- Removing stopwords helps focus on meaningful content\n",
    "- Improves the accuracy of tokenization "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "9e32ebf6-9c39-4063-a369-75b6c61b5288",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "9c7394f0-bfb9-401d-ac5d-39d075fac223",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['a',\n",
       " 'about',\n",
       " 'above',\n",
       " 'after',\n",
       " 'again',\n",
       " 'against',\n",
       " 'ain',\n",
       " 'all',\n",
       " 'am',\n",
       " 'an',\n",
       " 'and',\n",
       " 'any',\n",
       " 'are',\n",
       " 'aren',\n",
       " \"aren't\",\n",
       " 'as',\n",
       " 'at',\n",
       " 'be',\n",
       " 'because',\n",
       " 'been',\n",
       " 'before',\n",
       " 'being',\n",
       " 'below',\n",
       " 'between',\n",
       " 'both',\n",
       " 'but',\n",
       " 'by',\n",
       " 'can',\n",
       " 'couldn',\n",
       " \"couldn't\",\n",
       " 'd',\n",
       " 'did',\n",
       " 'didn',\n",
       " \"didn't\",\n",
       " 'do',\n",
       " 'does',\n",
       " 'doesn',\n",
       " \"doesn't\",\n",
       " 'doing',\n",
       " 'don',\n",
       " \"don't\",\n",
       " 'down',\n",
       " 'during',\n",
       " 'each',\n",
       " 'few',\n",
       " 'for',\n",
       " 'from',\n",
       " 'further',\n",
       " 'had',\n",
       " 'hadn',\n",
       " \"hadn't\",\n",
       " 'has',\n",
       " 'hasn',\n",
       " \"hasn't\",\n",
       " 'have',\n",
       " 'haven',\n",
       " \"haven't\",\n",
       " 'having',\n",
       " 'he',\n",
       " \"he'd\",\n",
       " \"he'll\",\n",
       " 'her',\n",
       " 'here',\n",
       " 'hers',\n",
       " 'herself',\n",
       " \"he's\",\n",
       " 'him',\n",
       " 'himself',\n",
       " 'his',\n",
       " 'how',\n",
       " 'i',\n",
       " \"i'd\",\n",
       " 'if',\n",
       " \"i'll\",\n",
       " \"i'm\",\n",
       " 'in',\n",
       " 'into',\n",
       " 'is',\n",
       " 'isn',\n",
       " \"isn't\",\n",
       " 'it',\n",
       " \"it'd\",\n",
       " \"it'll\",\n",
       " \"it's\",\n",
       " 'its',\n",
       " 'itself',\n",
       " \"i've\",\n",
       " 'just',\n",
       " 'll',\n",
       " 'm',\n",
       " 'ma',\n",
       " 'me',\n",
       " 'mightn',\n",
       " \"mightn't\",\n",
       " 'more',\n",
       " 'most',\n",
       " 'mustn',\n",
       " \"mustn't\",\n",
       " 'my',\n",
       " 'myself',\n",
       " 'needn',\n",
       " \"needn't\",\n",
       " 'no',\n",
       " 'nor',\n",
       " 'not',\n",
       " 'now',\n",
       " 'o',\n",
       " 'of',\n",
       " 'off',\n",
       " 'on',\n",
       " 'once',\n",
       " 'only',\n",
       " 'or',\n",
       " 'other',\n",
       " 'our',\n",
       " 'ours',\n",
       " 'ourselves',\n",
       " 'out',\n",
       " 'over',\n",
       " 'own',\n",
       " 're',\n",
       " 's',\n",
       " 'same',\n",
       " 'shan',\n",
       " \"shan't\",\n",
       " 'she',\n",
       " \"she'd\",\n",
       " \"she'll\",\n",
       " \"she's\",\n",
       " 'should',\n",
       " 'shouldn',\n",
       " \"shouldn't\",\n",
       " \"should've\",\n",
       " 'so',\n",
       " 'some',\n",
       " 'such',\n",
       " 't',\n",
       " 'than',\n",
       " 'that',\n",
       " \"that'll\",\n",
       " 'the',\n",
       " 'their',\n",
       " 'theirs',\n",
       " 'them',\n",
       " 'themselves',\n",
       " 'then',\n",
       " 'there',\n",
       " 'these',\n",
       " 'they',\n",
       " \"they'd\",\n",
       " \"they'll\",\n",
       " \"they're\",\n",
       " \"they've\",\n",
       " 'this',\n",
       " 'those',\n",
       " 'through',\n",
       " 'to',\n",
       " 'too',\n",
       " 'under',\n",
       " 'until',\n",
       " 'up',\n",
       " 've',\n",
       " 'very',\n",
       " 'was',\n",
       " 'wasn',\n",
       " \"wasn't\",\n",
       " 'we',\n",
       " \"we'd\",\n",
       " \"we'll\",\n",
       " \"we're\",\n",
       " 'were',\n",
       " 'weren',\n",
       " \"weren't\",\n",
       " \"we've\",\n",
       " 'what',\n",
       " 'when',\n",
       " 'where',\n",
       " 'which',\n",
       " 'while',\n",
       " 'who',\n",
       " 'whom',\n",
       " 'why',\n",
       " 'will',\n",
       " 'with',\n",
       " 'won',\n",
       " \"won't\",\n",
       " 'wouldn',\n",
       " \"wouldn't\",\n",
       " 'y',\n",
       " 'you',\n",
       " \"you'd\",\n",
       " \"you'll\",\n",
       " 'your',\n",
       " \"you're\",\n",
       " 'yours',\n",
       " 'yourself',\n",
       " 'yourselves',\n",
       " \"you've\"]"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stopwords.words('english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "334f4518-35fd-4056-8e7e-ad2e7be648ea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "198"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(stopwords.words('english'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "2737850d-cd82-4cb4-90d1-8f323dc1f6b1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['au',\n",
       " 'aux',\n",
       " 'avec',\n",
       " 'ce',\n",
       " 'ces',\n",
       " 'dans',\n",
       " 'de',\n",
       " 'des',\n",
       " 'du',\n",
       " 'elle',\n",
       " 'en',\n",
       " 'et',\n",
       " 'eux',\n",
       " 'il',\n",
       " 'ils',\n",
       " 'je',\n",
       " 'la',\n",
       " 'le',\n",
       " 'les',\n",
       " 'leur',\n",
       " 'lui',\n",
       " 'ma',\n",
       " 'mais',\n",
       " 'me',\n",
       " 'même',\n",
       " 'mes',\n",
       " 'moi',\n",
       " 'mon',\n",
       " 'ne',\n",
       " 'nos',\n",
       " 'notre',\n",
       " 'nous',\n",
       " 'on',\n",
       " 'ou',\n",
       " 'par',\n",
       " 'pas',\n",
       " 'pour',\n",
       " 'qu',\n",
       " 'que',\n",
       " 'qui',\n",
       " 'sa',\n",
       " 'se',\n",
       " 'ses',\n",
       " 'son',\n",
       " 'sur',\n",
       " 'ta',\n",
       " 'te',\n",
       " 'tes',\n",
       " 'toi',\n",
       " 'ton',\n",
       " 'tu',\n",
       " 'un',\n",
       " 'une',\n",
       " 'vos',\n",
       " 'votre',\n",
       " 'vous',\n",
       " 'c',\n",
       " 'd',\n",
       " 'j',\n",
       " 'l',\n",
       " 'à',\n",
       " 'm',\n",
       " 'n',\n",
       " 's',\n",
       " 't',\n",
       " 'y',\n",
       " 'été',\n",
       " 'étée',\n",
       " 'étées',\n",
       " 'étés',\n",
       " 'étant',\n",
       " 'étante',\n",
       " 'étants',\n",
       " 'étantes',\n",
       " 'suis',\n",
       " 'es',\n",
       " 'est',\n",
       " 'sommes',\n",
       " 'êtes',\n",
       " 'sont',\n",
       " 'serai',\n",
       " 'seras',\n",
       " 'sera',\n",
       " 'serons',\n",
       " 'serez',\n",
       " 'seront',\n",
       " 'serais',\n",
       " 'serait',\n",
       " 'serions',\n",
       " 'seriez',\n",
       " 'seraient',\n",
       " 'étais',\n",
       " 'était',\n",
       " 'étions',\n",
       " 'étiez',\n",
       " 'étaient',\n",
       " 'fus',\n",
       " 'fut',\n",
       " 'fûmes',\n",
       " 'fûtes',\n",
       " 'furent',\n",
       " 'sois',\n",
       " 'soit',\n",
       " 'soyons',\n",
       " 'soyez',\n",
       " 'soient',\n",
       " 'fusse',\n",
       " 'fusses',\n",
       " 'fût',\n",
       " 'fussions',\n",
       " 'fussiez',\n",
       " 'fussent',\n",
       " 'ayant',\n",
       " 'ayante',\n",
       " 'ayantes',\n",
       " 'ayants',\n",
       " 'eu',\n",
       " 'eue',\n",
       " 'eues',\n",
       " 'eus',\n",
       " 'ai',\n",
       " 'as',\n",
       " 'avons',\n",
       " 'avez',\n",
       " 'ont',\n",
       " 'aurai',\n",
       " 'auras',\n",
       " 'aura',\n",
       " 'aurons',\n",
       " 'aurez',\n",
       " 'auront',\n",
       " 'aurais',\n",
       " 'aurait',\n",
       " 'aurions',\n",
       " 'auriez',\n",
       " 'auraient',\n",
       " 'avais',\n",
       " 'avait',\n",
       " 'avions',\n",
       " 'aviez',\n",
       " 'avaient',\n",
       " 'eut',\n",
       " 'eûmes',\n",
       " 'eûtes',\n",
       " 'eurent',\n",
       " 'aie',\n",
       " 'aies',\n",
       " 'ait',\n",
       " 'ayons',\n",
       " 'ayez',\n",
       " 'aient',\n",
       " 'eusse',\n",
       " 'eusses',\n",
       " 'eût',\n",
       " 'eussions',\n",
       " 'eussiez',\n",
       " 'eussent']"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stopwords.words('french')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "d4c21fc5-b538-477a-a245-a92e8e011f27",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "157"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(stopwords.words('french'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "03316383-165d-4759-afdd-6cdad20de0ed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['aber',\n",
       " 'alle',\n",
       " 'allem',\n",
       " 'allen',\n",
       " 'aller',\n",
       " 'alles',\n",
       " 'als',\n",
       " 'also',\n",
       " 'am',\n",
       " 'an',\n",
       " 'ander',\n",
       " 'andere',\n",
       " 'anderem',\n",
       " 'anderen',\n",
       " 'anderer',\n",
       " 'anderes',\n",
       " 'anderm',\n",
       " 'andern',\n",
       " 'anderr',\n",
       " 'anders',\n",
       " 'auch',\n",
       " 'auf',\n",
       " 'aus',\n",
       " 'bei',\n",
       " 'bin',\n",
       " 'bis',\n",
       " 'bist',\n",
       " 'da',\n",
       " 'damit',\n",
       " 'dann',\n",
       " 'der',\n",
       " 'den',\n",
       " 'des',\n",
       " 'dem',\n",
       " 'die',\n",
       " 'das',\n",
       " 'dass',\n",
       " 'daß',\n",
       " 'derselbe',\n",
       " 'derselben',\n",
       " 'denselben',\n",
       " 'desselben',\n",
       " 'demselben',\n",
       " 'dieselbe',\n",
       " 'dieselben',\n",
       " 'dasselbe',\n",
       " 'dazu',\n",
       " 'dein',\n",
       " 'deine',\n",
       " 'deinem',\n",
       " 'deinen',\n",
       " 'deiner',\n",
       " 'deines',\n",
       " 'denn',\n",
       " 'derer',\n",
       " 'dessen',\n",
       " 'dich',\n",
       " 'dir',\n",
       " 'du',\n",
       " 'dies',\n",
       " 'diese',\n",
       " 'diesem',\n",
       " 'diesen',\n",
       " 'dieser',\n",
       " 'dieses',\n",
       " 'doch',\n",
       " 'dort',\n",
       " 'durch',\n",
       " 'ein',\n",
       " 'eine',\n",
       " 'einem',\n",
       " 'einen',\n",
       " 'einer',\n",
       " 'eines',\n",
       " 'einig',\n",
       " 'einige',\n",
       " 'einigem',\n",
       " 'einigen',\n",
       " 'einiger',\n",
       " 'einiges',\n",
       " 'einmal',\n",
       " 'er',\n",
       " 'ihn',\n",
       " 'ihm',\n",
       " 'es',\n",
       " 'etwas',\n",
       " 'euer',\n",
       " 'eure',\n",
       " 'eurem',\n",
       " 'euren',\n",
       " 'eurer',\n",
       " 'eures',\n",
       " 'für',\n",
       " 'gegen',\n",
       " 'gewesen',\n",
       " 'hab',\n",
       " 'habe',\n",
       " 'haben',\n",
       " 'hat',\n",
       " 'hatte',\n",
       " 'hatten',\n",
       " 'hier',\n",
       " 'hin',\n",
       " 'hinter',\n",
       " 'ich',\n",
       " 'mich',\n",
       " 'mir',\n",
       " 'ihr',\n",
       " 'ihre',\n",
       " 'ihrem',\n",
       " 'ihren',\n",
       " 'ihrer',\n",
       " 'ihres',\n",
       " 'euch',\n",
       " 'im',\n",
       " 'in',\n",
       " 'indem',\n",
       " 'ins',\n",
       " 'ist',\n",
       " 'jede',\n",
       " 'jedem',\n",
       " 'jeden',\n",
       " 'jeder',\n",
       " 'jedes',\n",
       " 'jene',\n",
       " 'jenem',\n",
       " 'jenen',\n",
       " 'jener',\n",
       " 'jenes',\n",
       " 'jetzt',\n",
       " 'kann',\n",
       " 'kein',\n",
       " 'keine',\n",
       " 'keinem',\n",
       " 'keinen',\n",
       " 'keiner',\n",
       " 'keines',\n",
       " 'können',\n",
       " 'könnte',\n",
       " 'machen',\n",
       " 'man',\n",
       " 'manche',\n",
       " 'manchem',\n",
       " 'manchen',\n",
       " 'mancher',\n",
       " 'manches',\n",
       " 'mein',\n",
       " 'meine',\n",
       " 'meinem',\n",
       " 'meinen',\n",
       " 'meiner',\n",
       " 'meines',\n",
       " 'mit',\n",
       " 'muss',\n",
       " 'musste',\n",
       " 'nach',\n",
       " 'nicht',\n",
       " 'nichts',\n",
       " 'noch',\n",
       " 'nun',\n",
       " 'nur',\n",
       " 'ob',\n",
       " 'oder',\n",
       " 'ohne',\n",
       " 'sehr',\n",
       " 'sein',\n",
       " 'seine',\n",
       " 'seinem',\n",
       " 'seinen',\n",
       " 'seiner',\n",
       " 'seines',\n",
       " 'selbst',\n",
       " 'sich',\n",
       " 'sie',\n",
       " 'ihnen',\n",
       " 'sind',\n",
       " 'so',\n",
       " 'solche',\n",
       " 'solchem',\n",
       " 'solchen',\n",
       " 'solcher',\n",
       " 'solches',\n",
       " 'soll',\n",
       " 'sollte',\n",
       " 'sondern',\n",
       " 'sonst',\n",
       " 'über',\n",
       " 'um',\n",
       " 'und',\n",
       " 'uns',\n",
       " 'unsere',\n",
       " 'unserem',\n",
       " 'unseren',\n",
       " 'unser',\n",
       " 'unseres',\n",
       " 'unter',\n",
       " 'viel',\n",
       " 'vom',\n",
       " 'von',\n",
       " 'vor',\n",
       " 'während',\n",
       " 'war',\n",
       " 'waren',\n",
       " 'warst',\n",
       " 'was',\n",
       " 'weg',\n",
       " 'weil',\n",
       " 'weiter',\n",
       " 'welche',\n",
       " 'welchem',\n",
       " 'welchen',\n",
       " 'welcher',\n",
       " 'welches',\n",
       " 'wenn',\n",
       " 'werde',\n",
       " 'werden',\n",
       " 'wie',\n",
       " 'wieder',\n",
       " 'will',\n",
       " 'wir',\n",
       " 'wird',\n",
       " 'wirst',\n",
       " 'wo',\n",
       " 'wollen',\n",
       " 'wollte',\n",
       " 'würde',\n",
       " 'würden',\n",
       " 'zu',\n",
       " 'zum',\n",
       " 'zur',\n",
       " 'zwar',\n",
       " 'zwischen']"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stopwords.words('german')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "d8166646-6f36-40e5-b4f9-e7c430db499b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "232"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(stopwords.words('german'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "a0945aeb-0c91-4468-a494-59cf67608190",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['一',\n",
       " '一下',\n",
       " '一些',\n",
       " '一切',\n",
       " '一则',\n",
       " '一天',\n",
       " '一定',\n",
       " '一方面',\n",
       " '一旦',\n",
       " '一时',\n",
       " '一来',\n",
       " '一样',\n",
       " '一次',\n",
       " '一片',\n",
       " '一直',\n",
       " '一致',\n",
       " '一般',\n",
       " '一起',\n",
       " '一边',\n",
       " '一面',\n",
       " '万一',\n",
       " '上下',\n",
       " '上升',\n",
       " '上去',\n",
       " '上来',\n",
       " '上述',\n",
       " '上面',\n",
       " '下列',\n",
       " '下去',\n",
       " '下来',\n",
       " '下面',\n",
       " '不一',\n",
       " '不久',\n",
       " '不仅',\n",
       " '不会',\n",
       " '不但',\n",
       " '不光',\n",
       " '不单',\n",
       " '不变',\n",
       " '不只',\n",
       " '不可',\n",
       " '不同',\n",
       " '不够',\n",
       " '不如',\n",
       " '不得',\n",
       " '不怕',\n",
       " '不惟',\n",
       " '不成',\n",
       " '不拘',\n",
       " '不敢',\n",
       " '不断',\n",
       " '不是',\n",
       " '不比',\n",
       " '不然',\n",
       " '不特',\n",
       " '不独',\n",
       " '不管',\n",
       " '不能',\n",
       " '不要',\n",
       " '不论',\n",
       " '不足',\n",
       " '不过',\n",
       " '不问',\n",
       " '与',\n",
       " '与其',\n",
       " '与否',\n",
       " '与此同时',\n",
       " '专门',\n",
       " '且',\n",
       " '两者',\n",
       " '严格',\n",
       " '严重',\n",
       " '个',\n",
       " '个人',\n",
       " '个别',\n",
       " '中小',\n",
       " '中间',\n",
       " '丰富',\n",
       " '临',\n",
       " '为',\n",
       " '为主',\n",
       " '为了',\n",
       " '为什么',\n",
       " '为什麽',\n",
       " '为何',\n",
       " '为着',\n",
       " '主张',\n",
       " '主要',\n",
       " '举行',\n",
       " '乃',\n",
       " '乃至',\n",
       " '么',\n",
       " '之',\n",
       " '之一',\n",
       " '之前',\n",
       " '之后',\n",
       " '之後',\n",
       " '之所以',\n",
       " '之类',\n",
       " '乌乎',\n",
       " '乎',\n",
       " '乘',\n",
       " '也',\n",
       " '也好',\n",
       " '也是',\n",
       " '也罢',\n",
       " '了',\n",
       " '了解',\n",
       " '争取',\n",
       " '于',\n",
       " '于是',\n",
       " '于是乎',\n",
       " '云云',\n",
       " '互相',\n",
       " '产生',\n",
       " '人们',\n",
       " '人家',\n",
       " '什么',\n",
       " '什么样',\n",
       " '什麽',\n",
       " '今后',\n",
       " '今天',\n",
       " '今年',\n",
       " '今後',\n",
       " '仍然',\n",
       " '从',\n",
       " '从事',\n",
       " '从而',\n",
       " '他',\n",
       " '他人',\n",
       " '他们',\n",
       " '他的',\n",
       " '代替',\n",
       " '以',\n",
       " '以上',\n",
       " '以下',\n",
       " '以为',\n",
       " '以便',\n",
       " '以免',\n",
       " '以前',\n",
       " '以及',\n",
       " '以后',\n",
       " '以外',\n",
       " '以後',\n",
       " '以来',\n",
       " '以至',\n",
       " '以至于',\n",
       " '以致',\n",
       " '们',\n",
       " '任',\n",
       " '任何',\n",
       " '任凭',\n",
       " '任务',\n",
       " '企图',\n",
       " '伟大',\n",
       " '似乎',\n",
       " '似的',\n",
       " '但',\n",
       " '但是',\n",
       " '何',\n",
       " '何况',\n",
       " '何处',\n",
       " '何时',\n",
       " '作为',\n",
       " '你',\n",
       " '你们',\n",
       " '你的',\n",
       " '使得',\n",
       " '使用',\n",
       " '例如',\n",
       " '依',\n",
       " '依照',\n",
       " '依靠',\n",
       " '促进',\n",
       " '保持',\n",
       " '俺',\n",
       " '俺们',\n",
       " '倘',\n",
       " '倘使',\n",
       " '倘或',\n",
       " '倘然',\n",
       " '倘若',\n",
       " '假使',\n",
       " '假如',\n",
       " '假若',\n",
       " '做到',\n",
       " '像',\n",
       " '允许',\n",
       " '充分',\n",
       " '先后',\n",
       " '先後',\n",
       " '先生',\n",
       " '全部',\n",
       " '全面',\n",
       " '兮',\n",
       " '共同',\n",
       " '关于',\n",
       " '其',\n",
       " '其一',\n",
       " '其中',\n",
       " '其二',\n",
       " '其他',\n",
       " '其余',\n",
       " '其它',\n",
       " '其实',\n",
       " '其次',\n",
       " '具体',\n",
       " '具体地说',\n",
       " '具体说来',\n",
       " '具有',\n",
       " '再者',\n",
       " '再说',\n",
       " '冒',\n",
       " '冲',\n",
       " '决定',\n",
       " '况且',\n",
       " '准备',\n",
       " '几',\n",
       " '几乎',\n",
       " '几时',\n",
       " '凭',\n",
       " '凭借',\n",
       " '出去',\n",
       " '出来',\n",
       " '出现',\n",
       " '分别',\n",
       " '则',\n",
       " '别',\n",
       " '别的',\n",
       " '别说',\n",
       " '到',\n",
       " '前后',\n",
       " '前者',\n",
       " '前进',\n",
       " '前面',\n",
       " '加之',\n",
       " '加以',\n",
       " '加入',\n",
       " '加强',\n",
       " '十分',\n",
       " '即',\n",
       " '即令',\n",
       " '即使',\n",
       " '即便',\n",
       " '即或',\n",
       " '即若',\n",
       " '却不',\n",
       " '原来',\n",
       " '又',\n",
       " '及',\n",
       " '及其',\n",
       " '及时',\n",
       " '及至',\n",
       " '双方',\n",
       " '反之',\n",
       " '反应',\n",
       " '反映',\n",
       " '反过来',\n",
       " '反过来说',\n",
       " '取得',\n",
       " '受到',\n",
       " '变成',\n",
       " '另',\n",
       " '另一方面',\n",
       " '另外',\n",
       " '只是',\n",
       " '只有',\n",
       " '只要',\n",
       " '只限',\n",
       " '叫',\n",
       " '叫做',\n",
       " '召开',\n",
       " '叮咚',\n",
       " '可',\n",
       " '可以',\n",
       " '可是',\n",
       " '可能',\n",
       " '可见',\n",
       " '各',\n",
       " '各个',\n",
       " '各人',\n",
       " '各位',\n",
       " '各地',\n",
       " '各种',\n",
       " '各级',\n",
       " '各自',\n",
       " '合理',\n",
       " '同',\n",
       " '同一',\n",
       " '同时',\n",
       " '同样',\n",
       " '后来',\n",
       " '后面',\n",
       " '向',\n",
       " '向着',\n",
       " '吓',\n",
       " '吗',\n",
       " '否则',\n",
       " '吧',\n",
       " '吧哒',\n",
       " '吱',\n",
       " '呀',\n",
       " '呃',\n",
       " '呕',\n",
       " '呗',\n",
       " '呜',\n",
       " '呜呼',\n",
       " '呢',\n",
       " '周围',\n",
       " '呵',\n",
       " '呸',\n",
       " '呼哧',\n",
       " '咋',\n",
       " '和',\n",
       " '咚',\n",
       " '咦',\n",
       " '咱',\n",
       " '咱们',\n",
       " '咳',\n",
       " '哇',\n",
       " '哈',\n",
       " '哈哈',\n",
       " '哉',\n",
       " '哎',\n",
       " '哎呀',\n",
       " '哎哟',\n",
       " '哗',\n",
       " '哟',\n",
       " '哦',\n",
       " '哩',\n",
       " '哪',\n",
       " '哪个',\n",
       " '哪些',\n",
       " '哪儿',\n",
       " '哪天',\n",
       " '哪年',\n",
       " '哪怕',\n",
       " '哪样',\n",
       " '哪边',\n",
       " '哪里',\n",
       " '哼',\n",
       " '哼唷',\n",
       " '唉',\n",
       " '啊',\n",
       " '啐',\n",
       " '啥',\n",
       " '啦',\n",
       " '啪达',\n",
       " '喂',\n",
       " '喏',\n",
       " '喔唷',\n",
       " '嗡嗡',\n",
       " '嗬',\n",
       " '嗯',\n",
       " '嗳',\n",
       " '嘎',\n",
       " '嘎登',\n",
       " '嘘',\n",
       " '嘛',\n",
       " '嘻',\n",
       " '嘿',\n",
       " '因',\n",
       " '因为',\n",
       " '因此',\n",
       " '因而',\n",
       " '固然',\n",
       " '在',\n",
       " '在下',\n",
       " '地',\n",
       " '坚决',\n",
       " '坚持',\n",
       " '基本',\n",
       " '处理',\n",
       " '复杂',\n",
       " '多',\n",
       " '多少',\n",
       " '多数',\n",
       " '多次',\n",
       " '大力',\n",
       " '大多数',\n",
       " '大大',\n",
       " '大家',\n",
       " '大批',\n",
       " '大约',\n",
       " '大量',\n",
       " '失去',\n",
       " '她',\n",
       " '她们',\n",
       " '她的',\n",
       " '好的',\n",
       " '好象',\n",
       " '如',\n",
       " '如上所述',\n",
       " '如下',\n",
       " '如何',\n",
       " '如其',\n",
       " '如果',\n",
       " '如此',\n",
       " '如若',\n",
       " '存在',\n",
       " '宁',\n",
       " '宁可',\n",
       " '宁愿',\n",
       " '宁肯',\n",
       " '它',\n",
       " '它们',\n",
       " '它们的',\n",
       " '它的',\n",
       " '安全',\n",
       " '完全',\n",
       " '完成',\n",
       " '实现',\n",
       " '实际',\n",
       " '宣布',\n",
       " '容易',\n",
       " '密切',\n",
       " '对',\n",
       " '对于',\n",
       " '对应',\n",
       " '将',\n",
       " '少数',\n",
       " '尔后',\n",
       " '尚且',\n",
       " '尤其',\n",
       " '就',\n",
       " '就是',\n",
       " '就是说',\n",
       " '尽',\n",
       " '尽管',\n",
       " '属于',\n",
       " '岂但',\n",
       " '左右',\n",
       " '巨大',\n",
       " '巩固',\n",
       " '己',\n",
       " '已经',\n",
       " '帮助',\n",
       " '常常',\n",
       " '并',\n",
       " '并不',\n",
       " '并不是',\n",
       " '并且',\n",
       " '并没有',\n",
       " '广大',\n",
       " '广泛',\n",
       " '应当',\n",
       " '应用',\n",
       " '应该',\n",
       " '开外',\n",
       " '开始',\n",
       " '开展',\n",
       " '引起',\n",
       " '强烈',\n",
       " '强调',\n",
       " '归',\n",
       " '当',\n",
       " '当前',\n",
       " '当时',\n",
       " '当然',\n",
       " '当着',\n",
       " '形成',\n",
       " '彻底',\n",
       " '彼',\n",
       " '彼此',\n",
       " '往',\n",
       " '往往',\n",
       " '待',\n",
       " '後来',\n",
       " '後面',\n",
       " '得',\n",
       " '得出',\n",
       " '得到',\n",
       " '心里',\n",
       " '必然',\n",
       " '必要',\n",
       " '必须',\n",
       " '怎',\n",
       " '怎么',\n",
       " '怎么办',\n",
       " '怎么样',\n",
       " '怎样',\n",
       " '怎麽',\n",
       " '总之',\n",
       " '总是',\n",
       " '总的来看',\n",
       " '总的来说',\n",
       " '总的说来',\n",
       " '总结',\n",
       " '总而言之',\n",
       " '恰恰相反',\n",
       " '您',\n",
       " '意思',\n",
       " '愿意',\n",
       " '慢说',\n",
       " '成为',\n",
       " '我',\n",
       " '我们',\n",
       " '我的',\n",
       " '或',\n",
       " '或是',\n",
       " '或者',\n",
       " '战斗',\n",
       " '所',\n",
       " '所以',\n",
       " '所有',\n",
       " '所谓',\n",
       " '打',\n",
       " '扩大',\n",
       " '把',\n",
       " '抑或',\n",
       " '拿',\n",
       " '按',\n",
       " '按照',\n",
       " '换句话说',\n",
       " '换言之',\n",
       " '据',\n",
       " '掌握',\n",
       " '接着',\n",
       " '接著',\n",
       " '故',\n",
       " '故此',\n",
       " '整个',\n",
       " '方便',\n",
       " '方面',\n",
       " '旁人',\n",
       " '无宁',\n",
       " '无法',\n",
       " '无论',\n",
       " '既',\n",
       " '既是',\n",
       " '既然',\n",
       " '时候',\n",
       " '明显',\n",
       " '明确',\n",
       " '是',\n",
       " '是否',\n",
       " '是的',\n",
       " '显然',\n",
       " '显著',\n",
       " '普通',\n",
       " '普遍',\n",
       " '更加',\n",
       " '曾经',\n",
       " '替',\n",
       " '最后',\n",
       " '最大',\n",
       " '最好',\n",
       " '最後',\n",
       " '最近',\n",
       " '最高',\n",
       " '有',\n",
       " '有些',\n",
       " '有关',\n",
       " '有利',\n",
       " '有力',\n",
       " '有所',\n",
       " '有效',\n",
       " '有时',\n",
       " '有点',\n",
       " '有的',\n",
       " '有着',\n",
       " '有著',\n",
       " '望',\n",
       " '朝',\n",
       " '朝着',\n",
       " '本',\n",
       " '本着',\n",
       " '来',\n",
       " '来着',\n",
       " '极了',\n",
       " '构成',\n",
       " '果然',\n",
       " '果真',\n",
       " '某',\n",
       " '某个',\n",
       " '某些',\n",
       " '根据',\n",
       " '根本',\n",
       " '欢迎',\n",
       " '正在',\n",
       " '正如',\n",
       " '正常',\n",
       " '此',\n",
       " '此外',\n",
       " '此时',\n",
       " '此间',\n",
       " '毋宁',\n",
       " '每',\n",
       " '每个',\n",
       " '每天',\n",
       " '每年',\n",
       " '每当',\n",
       " '比',\n",
       " '比如',\n",
       " '比方',\n",
       " '比较',\n",
       " '毫不',\n",
       " '没有',\n",
       " '沿',\n",
       " '沿着',\n",
       " '注意',\n",
       " '深入',\n",
       " '清楚',\n",
       " '满足',\n",
       " '漫说',\n",
       " '焉',\n",
       " '然则',\n",
       " '然后',\n",
       " '然後',\n",
       " '然而',\n",
       " '照',\n",
       " '照着',\n",
       " '特别是',\n",
       " '特殊',\n",
       " '特点',\n",
       " '现代',\n",
       " '现在',\n",
       " '甚么',\n",
       " '甚而',\n",
       " '甚至',\n",
       " '用',\n",
       " '由',\n",
       " '由于',\n",
       " '由此可见',\n",
       " '的',\n",
       " '的话',\n",
       " '目前',\n",
       " '直到',\n",
       " '直接',\n",
       " '相似',\n",
       " '相信',\n",
       " '相反',\n",
       " '相同',\n",
       " '相对',\n",
       " '相对而言',\n",
       " '相应',\n",
       " '相当',\n",
       " '相等',\n",
       " '省得',\n",
       " '看出',\n",
       " '看到',\n",
       " '看来',\n",
       " '看看',\n",
       " '看见',\n",
       " '真是',\n",
       " '真正',\n",
       " '着',\n",
       " '着呢',\n",
       " '矣',\n",
       " '知道',\n",
       " '确定',\n",
       " '离',\n",
       " '积极',\n",
       " '移动',\n",
       " '突出',\n",
       " '突然',\n",
       " '立即',\n",
       " '第',\n",
       " '等',\n",
       " '等等',\n",
       " '管',\n",
       " '紧接着',\n",
       " '纵',\n",
       " '纵令',\n",
       " '纵使',\n",
       " '纵然',\n",
       " '练习',\n",
       " '组成',\n",
       " '经',\n",
       " '经常',\n",
       " '经过',\n",
       " '结合',\n",
       " '结果',\n",
       " '给',\n",
       " '绝对',\n",
       " '继续',\n",
       " '继而',\n",
       " '维持',\n",
       " '综上所述',\n",
       " '罢了',\n",
       " '考虑',\n",
       " '者',\n",
       " '而',\n",
       " '而且',\n",
       " '而况',\n",
       " '而外',\n",
       " '而已',\n",
       " '而是',\n",
       " '而言',\n",
       " '联系',\n",
       " '能',\n",
       " '能否',\n",
       " '能够',\n",
       " '腾',\n",
       " '自',\n",
       " '自个儿',\n",
       " '自从',\n",
       " '自各儿',\n",
       " '自家',\n",
       " '自己',\n",
       " '自身',\n",
       " '至',\n",
       " '至于',\n",
       " '良好',\n",
       " '若',\n",
       " '若是',\n",
       " '若非',\n",
       " '范围',\n",
       " '莫若',\n",
       " '获得',\n",
       " '虽',\n",
       " '虽则',\n",
       " '虽然',\n",
       " '虽说',\n",
       " '行为',\n",
       " '行动',\n",
       " '表明',\n",
       " '表示',\n",
       " '被',\n",
       " '要',\n",
       " '要不',\n",
       " '要不是',\n",
       " '要不然',\n",
       " '要么',\n",
       " '要是',\n",
       " '要求',\n",
       " '规定',\n",
       " '觉得',\n",
       " '认为',\n",
       " '认真',\n",
       " '认识',\n",
       " '让',\n",
       " '许多',\n",
       " '论',\n",
       " '设使',\n",
       " '设若',\n",
       " '该',\n",
       " '说明',\n",
       " '诸位',\n",
       " '谁',\n",
       " '谁知',\n",
       " '赶',\n",
       " '起',\n",
       " '起来',\n",
       " '起见',\n",
       " '趁',\n",
       " '趁着',\n",
       " '越是',\n",
       " '跟',\n",
       " '转动',\n",
       " '转变',\n",
       " '转贴',\n",
       " '较',\n",
       " '较之',\n",
       " '边',\n",
       " '达到',\n",
       " '迅速',\n",
       " '过',\n",
       " '过去',\n",
       " '过来',\n",
       " '运用',\n",
       " '还是',\n",
       " '还有',\n",
       " '这',\n",
       " '这个',\n",
       " '这么',\n",
       " '这么些',\n",
       " '这么样',\n",
       " '这么点儿',\n",
       " '这些',\n",
       " '这会儿',\n",
       " '这儿',\n",
       " '这就是说',\n",
       " '这时',\n",
       " '这样',\n",
       " '这点',\n",
       " '这种',\n",
       " '这边',\n",
       " '这里',\n",
       " '这麽',\n",
       " '进入',\n",
       " '进步',\n",
       " '进而',\n",
       " '进行',\n",
       " '连',\n",
       " '连同',\n",
       " '适应',\n",
       " '适当',\n",
       " '适用',\n",
       " '逐步',\n",
       " '逐渐',\n",
       " '通常',\n",
       " '通过',\n",
       " '造成',\n",
       " '遇到',\n",
       " '遭到',\n",
       " '避免',\n",
       " '那',\n",
       " '那个',\n",
       " '那么',\n",
       " '那么些',\n",
       " '那么样',\n",
       " '那些',\n",
       " '那会儿',\n",
       " '那儿',\n",
       " '那时',\n",
       " '那样',\n",
       " '那边',\n",
       " '那里',\n",
       " '那麽',\n",
       " '部分',\n",
       " '鄙人',\n",
       " '采取',\n",
       " '里面',\n",
       " '重大',\n",
       " '重新',\n",
       " '重要',\n",
       " '鉴于',\n",
       " '问题',\n",
       " '防止',\n",
       " '阿',\n",
       " '附近',\n",
       " '限制',\n",
       " '除',\n",
       " '除了',\n",
       " '除此之外',\n",
       " '除非',\n",
       " '随',\n",
       " '随着',\n",
       " '随著',\n",
       " '集中',\n",
       " '需要',\n",
       " '非但',\n",
       " '非常',\n",
       " '非徒',\n",
       " '靠',\n",
       " '顺',\n",
       " '顺着',\n",
       " '首先',\n",
       " '高兴',\n",
       " '是不是']"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stopwords.words('chinese')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "0e9292d6-cf99-49e2-956b-4f397f0af8b5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "841"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(stopwords.words('chinese'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "db527a93-1fd1-4837-927c-e1171366d657",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['அங்கு',\n",
       " 'அங்கே',\n",
       " 'அடுத்த',\n",
       " 'அதனால்',\n",
       " 'அதன்',\n",
       " 'அதற்கு',\n",
       " 'அதிக',\n",
       " 'அதில்',\n",
       " 'அது',\n",
       " 'அதே',\n",
       " 'அதை',\n",
       " 'அந்த',\n",
       " 'அந்தக்',\n",
       " 'அந்தப்',\n",
       " 'அன்று',\n",
       " 'அல்லது',\n",
       " 'அவன்',\n",
       " 'அவரது',\n",
       " 'அவர்',\n",
       " 'அவர்கள்',\n",
       " 'அவள்',\n",
       " 'அவை',\n",
       " 'ஆகிய',\n",
       " 'ஆகியோர்',\n",
       " 'ஆகும்',\n",
       " 'இங்கு',\n",
       " 'இங்கே',\n",
       " 'இடத்தில்',\n",
       " 'இடம்',\n",
       " 'இதனால்',\n",
       " 'இதனை',\n",
       " 'இதன்',\n",
       " 'இதற்கு',\n",
       " 'இதில்',\n",
       " 'இது',\n",
       " 'இதை',\n",
       " 'இந்த',\n",
       " 'இந்தக்',\n",
       " 'இந்தத்',\n",
       " 'இந்தப்',\n",
       " 'இன்னும்',\n",
       " 'இப்போது',\n",
       " 'இரு',\n",
       " 'இருக்கும்',\n",
       " 'இருந்த',\n",
       " 'இருந்தது',\n",
       " 'இருந்து',\n",
       " 'இவர்',\n",
       " 'இவை',\n",
       " 'உன்',\n",
       " 'உள்ள',\n",
       " 'உள்ளது',\n",
       " 'உள்ளன',\n",
       " 'எந்த',\n",
       " 'என',\n",
       " 'எனக்',\n",
       " 'எனக்கு',\n",
       " 'எனப்படும்',\n",
       " 'எனவும்',\n",
       " 'எனவே',\n",
       " 'எனினும்',\n",
       " 'எனும்',\n",
       " 'என்',\n",
       " 'என்ன',\n",
       " 'என்னும்',\n",
       " 'என்பது',\n",
       " 'என்பதை',\n",
       " 'என்ற',\n",
       " 'என்று',\n",
       " 'என்றும்',\n",
       " 'எல்லாம்',\n",
       " 'ஏன்',\n",
       " 'ஒரு',\n",
       " 'ஒரே',\n",
       " 'ஓர்',\n",
       " 'கொண்ட',\n",
       " 'கொண்டு',\n",
       " 'கொள்ள',\n",
       " 'சற்று',\n",
       " 'சிறு',\n",
       " 'சில',\n",
       " 'சேர்ந்த',\n",
       " 'தனது',\n",
       " 'தன்',\n",
       " 'தவிர',\n",
       " 'தான்',\n",
       " 'நான்',\n",
       " 'நாம்',\n",
       " 'நீ',\n",
       " 'பற்றி',\n",
       " 'பற்றிய',\n",
       " 'பல',\n",
       " 'பலரும்',\n",
       " 'பல்வேறு',\n",
       " 'பின்',\n",
       " 'பின்னர்',\n",
       " 'பிற',\n",
       " 'பிறகு',\n",
       " 'பெரும்',\n",
       " 'பேர்',\n",
       " 'போது',\n",
       " 'போன்ற',\n",
       " 'போல',\n",
       " 'போல்',\n",
       " 'மட்டுமே',\n",
       " 'மட்டும்',\n",
       " 'மற்ற',\n",
       " 'மற்றும்',\n",
       " 'மிக',\n",
       " 'மிகவும்',\n",
       " 'மீது',\n",
       " 'முதல்',\n",
       " 'முறை',\n",
       " 'மேலும்',\n",
       " 'மேல்',\n",
       " 'யார்',\n",
       " 'வந்த',\n",
       " 'வந்து',\n",
       " 'வரும்',\n",
       " 'வரை',\n",
       " 'வரையில்',\n",
       " 'விட',\n",
       " 'விட்டு',\n",
       " 'வேண்டும்',\n",
       " 'வேறு']"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stopwords.words('tamil')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "fc4e1908-ebb5-4905-93c3-ec883f61636f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "125"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(stopwords.words('tamil'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "ccf83f2c-0190-4e93-88fb-56224d0041af",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['অতএব',\n",
       " 'অথচ',\n",
       " 'অথবা',\n",
       " 'অনুযায়ী',\n",
       " 'অনেক',\n",
       " 'অনেকে',\n",
       " 'অনেকেই',\n",
       " 'অন্তত',\n",
       " 'অন্য',\n",
       " 'অবধি',\n",
       " 'অবশ্য',\n",
       " 'অর্থাত',\n",
       " 'আই',\n",
       " 'আগামী',\n",
       " 'আগে',\n",
       " 'আগেই',\n",
       " 'আছে',\n",
       " 'আজ',\n",
       " 'আদ্যভাগে',\n",
       " 'আপনার',\n",
       " 'আপনি',\n",
       " 'আবার',\n",
       " 'আমরা',\n",
       " 'আমাকে',\n",
       " 'আমাদের',\n",
       " 'আমার',\n",
       " 'আমি',\n",
       " 'আর',\n",
       " 'আরও',\n",
       " 'ই',\n",
       " 'ইত্যাদি',\n",
       " 'ইহা',\n",
       " 'উচিত',\n",
       " 'উত্তর',\n",
       " 'উনি',\n",
       " 'উপর',\n",
       " 'উপরে',\n",
       " 'এ',\n",
       " 'এঁদের',\n",
       " 'এঁরা',\n",
       " 'এই',\n",
       " 'একই',\n",
       " 'একটি',\n",
       " 'একবার',\n",
       " 'একে',\n",
       " 'এক্',\n",
       " 'এখন',\n",
       " 'এখনও',\n",
       " 'এখানে',\n",
       " 'এখানেই',\n",
       " 'এটা',\n",
       " 'এটাই',\n",
       " 'এটি',\n",
       " 'এত',\n",
       " 'এতটাই',\n",
       " 'এতে',\n",
       " 'এদের',\n",
       " 'এব',\n",
       " 'এবং',\n",
       " 'এবার',\n",
       " 'এমন',\n",
       " 'এমনকী',\n",
       " 'এমনি',\n",
       " 'এর',\n",
       " 'এরা',\n",
       " 'এল',\n",
       " 'এস',\n",
       " 'এসে',\n",
       " 'ঐ',\n",
       " 'ও',\n",
       " 'ওঁদের',\n",
       " 'ওঁর',\n",
       " 'ওঁরা',\n",
       " 'ওই',\n",
       " 'ওকে',\n",
       " 'ওখানে',\n",
       " 'ওদের',\n",
       " 'ওর',\n",
       " 'ওরা',\n",
       " 'কখনও',\n",
       " 'কত',\n",
       " 'কবে',\n",
       " 'কমনে',\n",
       " 'কয়েক',\n",
       " 'কয়েকটি',\n",
       " 'করছে',\n",
       " 'করছেন',\n",
       " 'করতে',\n",
       " 'করবে',\n",
       " 'করবেন',\n",
       " 'করলে',\n",
       " 'করলেন',\n",
       " 'করা',\n",
       " 'করাই',\n",
       " 'করায়',\n",
       " 'করার',\n",
       " 'করি',\n",
       " 'করিতে',\n",
       " 'করিয়া',\n",
       " 'করিয়ে',\n",
       " 'করে',\n",
       " 'করেই',\n",
       " 'করেছিলেন',\n",
       " 'করেছে',\n",
       " 'করেছেন',\n",
       " 'করেন',\n",
       " 'কাউকে',\n",
       " 'কাছ',\n",
       " 'কাছে',\n",
       " 'কাজ',\n",
       " 'কাজে',\n",
       " 'কারও',\n",
       " 'কারণ',\n",
       " 'কি',\n",
       " 'কিংবা',\n",
       " 'কিছু',\n",
       " 'কিছুই',\n",
       " 'কিন্তু',\n",
       " 'কী',\n",
       " 'কে',\n",
       " 'কেউ',\n",
       " 'কেউই',\n",
       " 'কেখা',\n",
       " 'কেন',\n",
       " 'কোটি',\n",
       " 'কোন',\n",
       " 'কোনও',\n",
       " 'কোনো',\n",
       " 'ক্ষেত্রে',\n",
       " 'কয়েক',\n",
       " 'খুব',\n",
       " 'গিয়ে',\n",
       " 'গিয়েছে',\n",
       " 'গিয়ে',\n",
       " 'গুলি',\n",
       " 'গেছে',\n",
       " 'গেল',\n",
       " 'গেলে',\n",
       " 'গোটা',\n",
       " 'চলে',\n",
       " 'চান',\n",
       " 'চায়',\n",
       " 'চার',\n",
       " 'চালু',\n",
       " 'চেয়ে',\n",
       " 'চেষ্টা',\n",
       " 'ছাড়া',\n",
       " 'ছাড়াও',\n",
       " 'ছিল',\n",
       " 'ছিলেন',\n",
       " 'জন',\n",
       " 'জনকে',\n",
       " 'জনের',\n",
       " 'জন্য',\n",
       " 'জন্যওজে',\n",
       " 'জানতে',\n",
       " 'জানা',\n",
       " 'জানানো',\n",
       " 'জানায়',\n",
       " 'জানিয়ে',\n",
       " 'জানিয়েছে',\n",
       " 'জে',\n",
       " 'জ্নজন',\n",
       " 'টি',\n",
       " 'ঠিক',\n",
       " 'তখন',\n",
       " 'তত',\n",
       " 'তথা',\n",
       " 'তবু',\n",
       " 'তবে',\n",
       " 'তা',\n",
       " 'তাঁকে',\n",
       " 'তাঁদের',\n",
       " 'তাঁর',\n",
       " 'তাঁরা',\n",
       " 'তাঁাহারা',\n",
       " 'তাই',\n",
       " 'তাও',\n",
       " 'তাকে',\n",
       " 'তাতে',\n",
       " 'তাদের',\n",
       " 'তার',\n",
       " 'তারপর',\n",
       " 'তারা',\n",
       " 'তারৈ',\n",
       " 'তাহলে',\n",
       " 'তাহা',\n",
       " 'তাহাতে',\n",
       " 'তাহার',\n",
       " 'তিনঐ',\n",
       " 'তিনি',\n",
       " 'তিনিও',\n",
       " 'তুমি',\n",
       " 'তুলে',\n",
       " 'তেমন',\n",
       " 'তো',\n",
       " 'তোমার',\n",
       " 'থাকবে',\n",
       " 'থাকবেন',\n",
       " 'থাকা',\n",
       " 'থাকায়',\n",
       " 'থাকে',\n",
       " 'থাকেন',\n",
       " 'থেকে',\n",
       " 'থেকেই',\n",
       " 'থেকেও',\n",
       " 'দিকে',\n",
       " 'দিতে',\n",
       " 'দিন',\n",
       " 'দিয়ে',\n",
       " 'দিয়েছে',\n",
       " 'দিয়েছেন',\n",
       " 'দিলেন',\n",
       " 'দু',\n",
       " 'দুই',\n",
       " 'দুটি',\n",
       " 'দুটো',\n",
       " 'দেওয়া',\n",
       " 'দেওয়ার',\n",
       " 'দেওয়া',\n",
       " 'দেখতে',\n",
       " 'দেখা',\n",
       " 'দেখে',\n",
       " 'দেন',\n",
       " 'দেয়',\n",
       " 'দ্বারা',\n",
       " 'ধরা',\n",
       " 'ধরে',\n",
       " 'ধামার',\n",
       " 'নতুন',\n",
       " 'নয়',\n",
       " 'না',\n",
       " 'নাই',\n",
       " 'নাকি',\n",
       " 'নাগাদ',\n",
       " 'নানা',\n",
       " 'নিজে',\n",
       " 'নিজেই',\n",
       " 'নিজেদের',\n",
       " 'নিজের',\n",
       " 'নিতে',\n",
       " 'নিয়ে',\n",
       " 'নিয়ে',\n",
       " 'নেই',\n",
       " 'নেওয়া',\n",
       " 'নেওয়ার',\n",
       " 'নেওয়া',\n",
       " 'নয়',\n",
       " 'পক্ষে',\n",
       " 'পর',\n",
       " 'পরে',\n",
       " 'পরেই',\n",
       " 'পরেও',\n",
       " 'পর্যন্ত',\n",
       " 'পাওয়া',\n",
       " 'পাচ',\n",
       " 'পারি',\n",
       " 'পারে',\n",
       " 'পারেন',\n",
       " 'পি',\n",
       " 'পেয়ে',\n",
       " 'পেয়্র্',\n",
       " 'প্রতি',\n",
       " 'প্রথম',\n",
       " 'প্রভৃতি',\n",
       " 'প্রযন্ত',\n",
       " 'প্রাথমিক',\n",
       " 'প্রায়',\n",
       " 'প্রায়',\n",
       " 'ফলে',\n",
       " 'ফিরে',\n",
       " 'ফের',\n",
       " 'বক্তব্য',\n",
       " 'বদলে',\n",
       " 'বন',\n",
       " 'বরং',\n",
       " 'বলতে',\n",
       " 'বলল',\n",
       " 'বললেন',\n",
       " 'বলা',\n",
       " 'বলে',\n",
       " 'বলেছেন',\n",
       " 'বলেন',\n",
       " 'বসে',\n",
       " 'বহু',\n",
       " 'বা',\n",
       " 'বাদে',\n",
       " 'বার',\n",
       " 'বি',\n",
       " 'বিনা',\n",
       " 'বিভিন্ন',\n",
       " 'বিশেষ',\n",
       " 'বিষয়টি',\n",
       " 'বেশ',\n",
       " 'বেশি',\n",
       " 'ব্যবহার',\n",
       " 'ব্যাপারে',\n",
       " 'ভাবে',\n",
       " 'ভাবেই',\n",
       " 'মতো',\n",
       " 'মতোই',\n",
       " 'মধ্যভাগে',\n",
       " 'মধ্যে',\n",
       " 'মধ্যেই',\n",
       " 'মধ্যেও',\n",
       " 'মনে',\n",
       " 'মাত্র',\n",
       " 'মাধ্যমে',\n",
       " 'মোট',\n",
       " 'মোটেই',\n",
       " 'যখন',\n",
       " 'যত',\n",
       " 'যতটা',\n",
       " 'যথেষ্ট',\n",
       " 'যদি',\n",
       " 'যদিও',\n",
       " 'যা',\n",
       " 'যাঁর',\n",
       " 'যাঁরা',\n",
       " 'যাওয়া',\n",
       " 'যাওয়ার',\n",
       " 'যাওয়া',\n",
       " 'যাকে',\n",
       " 'যাচ্ছে',\n",
       " 'যাতে',\n",
       " 'যাদের',\n",
       " 'যান',\n",
       " 'যাবে',\n",
       " 'যায়',\n",
       " 'যার',\n",
       " 'যারা',\n",
       " 'যিনি',\n",
       " 'যে',\n",
       " 'যেখানে',\n",
       " 'যেতে',\n",
       " 'যেন',\n",
       " 'যেমন',\n",
       " 'র',\n",
       " 'রকম',\n",
       " 'রয়েছে',\n",
       " 'রাখা',\n",
       " 'রেখে',\n",
       " 'লক্ষ',\n",
       " 'শুধু',\n",
       " 'শুরু',\n",
       " 'সঙ্গে',\n",
       " 'সঙ্গেও',\n",
       " 'সব',\n",
       " 'সবার',\n",
       " 'সমস্ত',\n",
       " 'সম্প্রতি',\n",
       " 'সহ',\n",
       " 'সহিত',\n",
       " 'সাধারণ',\n",
       " 'সামনে',\n",
       " 'সি',\n",
       " 'সুতরাং',\n",
       " 'সে',\n",
       " 'সেই',\n",
       " 'সেখান',\n",
       " 'সেখানে',\n",
       " 'সেটা',\n",
       " 'সেটাই',\n",
       " 'সেটাও',\n",
       " 'সেটি',\n",
       " 'স্পষ্ট',\n",
       " 'স্বয়ং',\n",
       " 'হইতে',\n",
       " 'হইবে',\n",
       " 'হইয়া',\n",
       " 'হওয়া',\n",
       " 'হওয়ায়',\n",
       " 'হওয়ার',\n",
       " 'হচ্ছে',\n",
       " 'হত',\n",
       " 'হতে',\n",
       " 'হতেই',\n",
       " 'হন',\n",
       " 'হবে',\n",
       " 'হবেন',\n",
       " 'হয়',\n",
       " 'হয়তো',\n",
       " 'হয়নি',\n",
       " 'হয়ে',\n",
       " 'হয়েই',\n",
       " 'হয়েছিল',\n",
       " 'হয়েছে',\n",
       " 'হয়েছেন',\n",
       " 'হল',\n",
       " 'হলে',\n",
       " 'হলেই',\n",
       " 'হলেও',\n",
       " 'হলো',\n",
       " 'হাজার',\n",
       " 'হিসাবে',\n",
       " 'হৈলে',\n",
       " 'হোক',\n",
       " 'হয়']"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stopwords.words('bengali')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "3d2d545d-a960-4204-8380-2f7dc0c13419",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "398"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(stopwords.words('bengali'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b65cc045-0343-4ec6-83bd-2dd16a3b49e8",
   "metadata": {},
   "source": [
    "# POS Tagging\n",
    "-Definition: Assigns grammatical labels (noun, verb, adjective, etc.) to each token in a sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "f2eef5cd-ddff-4153-948b-1882a5b21724",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['sam', 'is', 'a', 'natural', 'when', 'it', 'comes', 'to', 'drawing']"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sent = 'sam is a natural when it comes to drawing'\n",
    "sent_tokens = word_tokenize(sent)\n",
    "sent_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "8edd680c-4a61-4caa-845b-b5316d442264",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import sent_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "a3020c53-e730-4899-a423-a574a6c377de",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Artificial Intelligence refers to the intelligence of machines.',\n",
       " 'This is in contrast to the natural intelligence of\\nhumans and animals.',\n",
       " 'With Artificial Intelligence, machines perform functions such as learning, planning, reasoning and\\nproblem-solving.',\n",
       " 'Most noteworthy, Artificial Intelligence is the simulation of human intelligence by machines.',\n",
       " 'It is probably the fastest-growing development in the World of technology and innovation.',\n",
       " 'Furthermore, many experts believe\\nAI could solve major challenges and crisis situations.']"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "AI_sent = sent_tokenize(AI)\n",
    "AI_sent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "0015cc17-07f5-4aa3-9600-50976e91c569",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('sam', 'NN')]\n",
      "[('is', 'VBZ')]\n",
      "[('a', 'DT')]\n",
      "[('natural', 'JJ')]\n",
      "[('when', 'WRB')]\n",
      "[('it', 'PRP')]\n",
      "[('comes', 'VBZ')]\n",
      "[('to', 'TO')]\n",
      "[('drawing', 'VBG')]\n"
     ]
    }
   ],
   "source": [
    "for token in sent_tokens:\n",
    "    print(nltk.pos_tag([token]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba98c1ce-c661-45ff-acf5-c251d2b0f90b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
