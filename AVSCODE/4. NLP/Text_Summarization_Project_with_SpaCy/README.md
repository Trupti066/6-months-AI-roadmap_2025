
# ğŸ“ Text Summarizer (spaCy + Streamlit)

An **Extractive Text Summarization App** built as part of my NLP journey ğŸš€.  
This project falls under **Natural Language Processing (NLP)** â€” the branch of AI that helps computers understand, interpret, and generate human language.  

With this app, users can **paste text** or **upload documents** (`.txt`, `.pdf`, `.docx`) and instantly get a concise summary.  
Itâ€™s simple, interactive, and showcases the power of NLP in real-world applications.  

---

## ğŸ“Œ What This Project Does
- Accepts **raw text or uploaded files** (TXT, PDF, DOCX)  
- Uses **spaCy NLP pipeline** to process the content  
- Removes stopwords & punctuation, builds a **word frequency table**  
- Scores sentences and extracts the most informative ones  
- Lets users **control summary ratio** (10â€“90%) and **set min/max sentences**  
- Presents the final summary through a clean **Streamlit frontend**  

---

## ğŸ§  Why This Matters (NLP Context)
Text Summarization is a **core NLP task** that saves time by reducing large documents into their **key insights**.  
This project uses **Extractive Summarization**, where important sentences are pulled directly from the text (instead of generating new ones).  

ğŸ‘‰ Applications of NLP Summarization:
- ğŸ“š Education: Summarizing long study notes or research papers  
- ğŸ“° Media: Condensing news articles into quick reads  
- ğŸ’¼ Business: Creating short reports from long documents  
- âš–ï¸ Legal: Reducing lengthy case documents into highlights  

---

## âš™ï¸ Tech Stack
- **Python 3** ğŸ  
- **spaCy** (`en_core_web_sm`) for NLP  
- **Streamlit** for frontend UI  
- **pdfplumber** â†’ Extract text from PDFs  
- **python-docx** â†’ Extract text from Word files  
- **heapq (nlargest)** â†’ Select top-ranked sentences  

---

## ğŸ“Š How It Works (Behind the Scenes)

1. **Tokenization** â€“ Split text into words and sentences using spaCy  
2. **Stopword & Punctuation Removal** â€“ Clean noisy tokens  
3. **Word Frequency Calculation** â€“ Count how often each word occurs  
4. **Normalization** â€“ Scale frequencies between 0 and 1  
5. **Sentence Scoring** â€“ Add up scores of words in each sentence  
6. **Ranking** â€“ Select top sentences based on ratio or min length  
7. **Final Summary** â€“ Output sentences in original order  

---

## ğŸ“· Screenshots

### 1ï¸âƒ£ Overall App Look
![App Look](Out_1.PNG)

### 2ï¸âƒ£ Upload File & Generate Summary
![Uploaded File Result](Out_2.PNG)

### 3ï¸âƒ£ Summary Length = 50%
![Summary 50%](Out_3.PNG)

### 4ï¸âƒ£ Minimum Sentences = 2
![2 Sentences](Out_4.PNG)

---

## ğŸš€ Installation & Run

1. Clone this repo:
```bash
   git clone https://github.com/your-username/text-summarizer.git
   cd text-summarizer
```

2. Install dependencies:
```bash
 pip install -r requirements.txt
```

3. Download spaCy model:
```bash
   python -m spacy download en_core_web_sm
```

4. Run the app:
 ```bash
   streamlit run app.py
```
---

## ğŸŒŸ Future Enhancements

* Add **Abstractive Summarization** using Transformers (BART, T5)
* Add **Named Entity Recognition (NER)** highlighting in summary
* Export summary as `.txt` or `.pdf`
* Support for **multiple languages**

---

## ğŸ™Œ Author

**Akshay Bhujbal**
ğŸ“Œ Project as part of **100 Days of AI/Data**
ğŸ¯ Exploring **NLP, spaCy, and Streamlit**


